<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine_learning - Chris Albon</title>
    <link>https://chrisalbon.com/machine_learning/index.xml</link>
    <description></description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Apr 2021 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://chrisalbon.com/machine_learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Create simulated data for clustering</title>
      <link>https://chrisalbon.com/machine_learning/basics/create_simulated_data_for_clustering_blobs/</link>
      <pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/basics/create_simulated_data_for_clustering_blobs/</guid>
      <description>Create simulated data for clustering (blobs) Imports from sklearn.datasets import make_blobs import matplotlib.pyplot as plt import numpy as np Create data # Make features (data) and label (labels) data, labels = make_blobs(n_samples = 200, n_features = 2, centers = 3, # 3 clusters cluster_std = 0.5, shuffle =True) Set up colours from itertools import islice, cycle color_list = [&amp;#39;#377eb8&amp;#39;, &amp;#39;#ff7f00&amp;#39;, &amp;#39;#4daf4a&amp;#39;, &amp;#39;#f781bf&amp;#39;, &amp;#39;#a65628&amp;#39;, &amp;#39;#984ea3&amp;#39;, &amp;#39;#999999&amp;#39;, &amp;#39;#e41a1c&amp;#39;, &amp;#39;#dede00&amp;#39;] amount_of_labels = int(max(labels) + 1) colors = np.</description>
    </item>
    
    <item>
      <title>Create simulated data for regression</title>
      <link>https://chrisalbon.com/machine_learning/basics/create_simulated_data_for_regression/</link>
      <pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/basics/create_simulated_data_for_regression/</guid>
      <description>Creating simulated data for regression Generate a problem set for regression with make_regression.
Imports import pandas as pd from sklearn.datasets import make_regression Create data n_samples = 100 n_features = 1 X, y, coeff = make_regression(n_samples=n_samples, n_features=n_features, noise = 10, coef=True) View data pd.DataFrame(X).head()  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  
  0     0 -0.</description>
    </item>
    
    <item>
      <title>Create simulated data moons</title>
      <link>https://chrisalbon.com/machine_learning/basics/create_simulated_data_moons/</link>
      <pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/basics/create_simulated_data_moons/</guid>
      <description>Create simulate data moons Imports from itertools import cycle, islice from sklearn.datasets import make_moons Create data Generate X and y where X is the position and label is the label.
X, labels = make_moons(noise=0.1) Generate colormap (what the fuck?) colors = np.array(list(islice(cycle([&amp;#39;#377eb8&amp;#39;, &amp;#39;#ff7f00&amp;#39;, &amp;#39;#4daf4a&amp;#39;, &amp;#39;#f781bf&amp;#39;, &amp;#39;#a65628&amp;#39;, &amp;#39;#984ea3&amp;#39;, &amp;#39;#999999&amp;#39;, &amp;#39;#e41a1c&amp;#39;, &amp;#39;#dede00&amp;#39;]), int(max(label) + 1)))) View data import matplotlib.pyplot as plt x = X[:,0] y = X[:,1] plt.scatter(x, y, color=colors[labels]) plt.show() </description>
    </item>
    
    <item>
      <title>Loading keras imdb dataset</title>
      <link>https://chrisalbon.com/machine_learning/basics/loading_keras_imdb_dataset/</link>
      <pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/basics/loading_keras_imdb_dataset/</guid>
      <description>Loading Keras IMDB dataset import numpy as np import pandas as pd from keras.datasets import imdb from keras.preprocessing.text import Tokenizer This downloads 25.000 movie reviews from IMDB with the label positive/negative.
Each review is encoded as a list of indexes (integers)
Words are encoded by overall frequency in the dataset. Integer 3 encodes the 3rd most frequent word in the data.
Create data # set number of features (use top 1000 words) num_words = 1000 index_from = 3 # load data (x_train, y_train), (x_test, y_test) = imdb.</description>
    </item>
    
    <item>
      <title>Loading scikit learn iris dataset</title>
      <link>https://chrisalbon.com/machine_learning/basics/loading_scikit_learn_iris_dataset/</link>
      <pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/basics/loading_scikit_learn_iris_dataset/</guid>
      <description>Loading scikit-learn Iris dataset from sklearn import datasets import numpy as np Load Iris Dataset The Iris flower dataset is one of the most famous databases for classification.
The dataset contains:
 3 classes (species of flowers) 50 observations per class  # Load Iris datset iris = datasets.load_iris() # Create features X = iris.data # Create label y = iris.target # View first row X[0] array([5.1, 3.5, 1.4, 0.2])  Option 2: Load as frame # np.</description>
    </item>
    
    <item>
      <title>Loading scikit-learn boston housing dataset</title>
      <link>https://chrisalbon.com/machine_learning/basics/loading_scikit_learn_boston_housing_dataset/</link>
      <pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/basics/loading_scikit_learn_boston_housing_dataset/</guid>
      <description>Loading scikit-learn Boston housing dataset import numpy as np import pandas as pd from sklearn import datasets Load Boston Housing Dataset The Boston housing dataset is a famous dataset from the 1970s. It contains 506 observations on housing prices around Boston. It is often used in regression examples and contains 15 features.
boston = datasets.load_boston() # Load features X = boston.data # Load data y = boston.target # View first observation X[0] array([6.</description>
    </item>
    
    <item>
      <title>Loading scikit-learn digits dataset</title>
      <link>https://chrisalbon.com/machine_learning/basics/loading_scikit_learn_digits_dataset/</link>
      <pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/basics/loading_scikit_learn_digits_dataset/</guid>
      <description>Loading scikit-learn digits dataset from sklearn import datasets import matplotlib.pyplot as plt Load digits dataset The Digits dataset is a dataset of handwritten digits. Each feature is the intensity of a single pixel in an 8x8 image.
# Load digits = datasets.load_digits() # View attributes dir(digits) [&#39;DESCR&#39;, &#39;data&#39;, &#39;images&#39;, &#39;target&#39;, &#39;target_names&#39;]  # Create features X = digits.data # Create target label y = digits.target Each of the futures are represented as a vector of length 64 instead of an 8x8 image.</description>
    </item>
    
  </channel>
</rss>